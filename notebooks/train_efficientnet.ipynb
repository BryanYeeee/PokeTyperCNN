{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8065b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data generators for the training and validation sets\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath('../utils')\n",
    "print(\"Adding to sys.path:\", module_path)\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from data_prep import get_data_generators\n",
    "train_gen, valid_gen, full_gen, _ = get_data_generators('../data/pokemon.csv', '../data/pokemon-img/pokemon/pokemon/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fee183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x, y = next(train_gen)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "plt.imshow(x[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510862e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\halod\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\halod\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional  (None, 7, 7, 1280)        4049571   \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4215861 (16.08 MB)\n",
      "Trainable params: 166290 (649.57 KB)\n",
      "Non-trainable params: 4049571 (15.45 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# defining the model based on the base model\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Precision,Recall, AUC\n",
    "\n",
    "# freeze the base\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(18, activation='sigmoid')  # 18 is the number of pokemon types so 18 classes\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=BinaryCrossentropy(),\n",
    "    metrics=[AUC(name='auc', multi_label=True), Precision(name='precision'), Recall(name='recall')]\n",
    "\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db7d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\halod\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "18/18 [==============================] - 15s 586ms/step - loss: 0.6221 - auc: 0.4937 - precision: 0.0670 - recall: 0.2007 - val_loss: 0.5396 - val_auc: 0.5138 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 11s 604ms/step - loss: 0.5028 - auc: 0.5018 - precision: 0.0770 - recall: 0.0554 - val_loss: 0.4367 - val_auc: 0.5003 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 12s 670ms/step - loss: 0.4218 - auc: 0.4974 - precision: 0.0742 - recall: 0.0196 - val_loss: 0.3637 - val_auc: 0.5047 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 12s 676ms/step - loss: 0.3664 - auc: 0.5095 - precision: 0.0678 - recall: 0.0092 - val_loss: 0.3178 - val_auc: 0.4889 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 12s 672ms/step - loss: 0.3301 - auc: 0.5111 - precision: 0.1628 - recall: 0.0081 - val_loss: 0.2947 - val_auc: 0.4899 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.3194 - auc: 0.4936 - precision: 0.1250 - recall: 0.0035 - val_loss: 0.2850 - val_auc: 0.4827 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 12s 677ms/step - loss: 0.3131 - auc: 0.4932 - precision: 0.0625 - recall: 0.0012 - val_loss: 0.2808 - val_auc: 0.4998 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 13s 696ms/step - loss: 0.3131 - auc: 0.4818 - precision: 0.0769 - recall: 0.0012 - val_loss: 0.2793 - val_auc: 0.4921 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 12s 660ms/step - loss: 0.3078 - auc: 0.4970 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2780 - val_auc: 0.4979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 12s 649ms/step - loss: 0.3074 - auc: 0.4924 - precision: 0.0625 - recall: 0.0012 - val_loss: 0.2776 - val_auc: 0.5094 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 12s 658ms/step - loss: 0.3040 - auc: 0.5026 - precision: 0.1667 - recall: 0.0023 - val_loss: 0.2770 - val_auc: 0.4911 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 12s 657ms/step - loss: 0.3054 - auc: 0.5003 - precision: 0.1818 - recall: 0.0023 - val_loss: 0.2773 - val_auc: 0.4980 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 9s 514ms/step - loss: 0.2996 - auc: 0.5174 - precision: 0.1000 - recall: 0.0012 - val_loss: 0.2773 - val_auc: 0.5064 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 12s 638ms/step - loss: 0.3040 - auc: 0.5035 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2764 - val_auc: 0.5016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 11s 610ms/step - loss: 0.3056 - auc: 0.4749 - precision: 0.1667 - recall: 0.0012 - val_loss: 0.2765 - val_auc: 0.4964 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 9s 517ms/step - loss: 0.2991 - auc: 0.5250 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2765 - val_auc: 0.5036 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 9s 502ms/step - loss: 0.3025 - auc: 0.5040 - precision: 0.2500 - recall: 0.0012 - val_loss: 0.2765 - val_auc: 0.4972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 9s 519ms/step - loss: 0.3036 - auc: 0.4931 - precision: 0.1111 - recall: 0.0012 - val_loss: 0.2761 - val_auc: 0.5022 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 9s 497ms/step - loss: 0.3029 - auc: 0.4855 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2762 - val_auc: 0.5065 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 12s 658ms/step - loss: 0.3018 - auc: 0.4965 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2763 - val_auc: 0.5008 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 12s 658ms/step - loss: 0.3064 - auc: 0.4694 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2763 - val_auc: 0.5016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 12s 676ms/step - loss: 0.3028 - auc: 0.4911 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2763 - val_auc: 0.5004 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 12s 663ms/step - loss: 0.3018 - auc: 0.4919 - precision: 0.2857 - recall: 0.0023 - val_loss: 0.2762 - val_auc: 0.4994 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 12s 649ms/step - loss: 0.3010 - auc: 0.5012 - precision: 0.2500 - recall: 0.0012 - val_loss: 0.2761 - val_auc: 0.4953 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 12s 652ms/step - loss: 0.3019 - auc: 0.4960 - precision: 0.4000 - recall: 0.0023 - val_loss: 0.2761 - val_auc: 0.5018 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.2500e-05\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 12s 658ms/step - loss: 0.3012 - auc: 0.4923 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2762 - val_auc: 0.5029 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.2500e-05\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 10s 538ms/step - loss: 0.3035 - auc: 0.4800 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2762 - val_auc: 0.4990 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.2500e-05\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 10s 538ms/step - loss: 0.3019 - auc: 0.4903 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2762 - val_auc: 0.4973 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 6.2500e-06\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 12s 641ms/step - loss: 0.2986 - auc: 0.5156 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2762 - val_auc: 0.4947 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 6.2500e-06\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 12s 684ms/step - loss: 0.3003 - auc: 0.4990 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2762 - val_auc: 0.5027 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 6.2500e-06\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 11s 625ms/step - loss: 0.2985 - auc: 0.5122 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2762 - val_auc: 0.5002 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.1250e-06\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 12s 642ms/step - loss: 0.3021 - auc: 0.4923 - precision: 1.0000 - recall: 0.0023 - val_loss: 0.2762 - val_auc: 0.4972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.1250e-06\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 12s 642ms/step - loss: 0.3009 - auc: 0.4961 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2762 - val_auc: 0.5020 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.1250e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=50,  # longer, EarlyStopping will stop if plateau\n",
    "    callbacks=[EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,       # stop if no improvement for 5 epochs\n",
    "        restore_best_weights=True\n",
    "    ), ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,       # reduce LR by half\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    )]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
